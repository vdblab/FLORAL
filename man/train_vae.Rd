% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/py_wrapper.R
\name{train_vae}
\alias{train_vae}
\title{Train VAE using PyTorch (replacement for R torch version)}
\usage{
train_vae(
  x,
  latent_dim = 32,
  lambda_kl = 0,
  lambda_abun = 0,
  lambda_pres = 0,
  gamma_full = 1,
  gamma_swap = 1,
  lambda_moments = 0,
  delta_corr = 0,
  sigma_list = c(1, 2, 4, 8, 16, 32, 64, 128),
  epochs = 100,
  batch_size = 50,
  lr = 0.001,
  weight_decay = 0.01,
  seed = 123
)
}
\arguments{
\item{x}{Input data matrix (n_samples x n_features)}

\item{latent_dim}{Dimension of latent space (default: 32)}

\item{lambda_kl}{Weight for KL divergence loss (default: 0)}

\item{lambda_abun}{Weight for abundance loss (default: 0)}

\item{lambda_pres}{Weight for presence loss (default: 0)}

\item{gamma_full}{Weight for MMD full loss (default: 1)}

\item{gamma_swap}{Weight for MMD swap loss (default: 1)}

\item{lambda_moments}{Weight for moment matching loss (default: 0)}

\item{delta_corr}{Weight for correlation loss (default: 0)}

\item{sigma_list}{List of sigma values for MMD kernel (default: c(1,2,4,8,16,32,64,128))}

\item{epochs}{Number of training epochs (default: 100)}

\item{batch_size}{Batch size for training (default: 50)}

\item{lr}{Learning rate (default: 1e-3)}

\item{weight_decay}{Weight decay for optimizer (default: 1e-2)}

\item{seed}{Random seed (default: 123)}
}
\value{
A list with components:
  \item{knockoff_x}{Generated knockoff data matrix}
  \item{recon_x}{Reconstructed data matrix}
}
\description{
This function wraps the Python PyTorch implementation of VAE_func_DK,
providing the same interface as the original R torch version.
}
